[2024-06-17T11:19:17.591+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T11:19:17.711+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ELT-PROJECT.load_process.load_suppliers manual__2024-06-17T11:13:55.745913+00:00 [queued]>
[2024-06-17T11:19:17.760+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ELT-PROJECT.load_process.load_suppliers manual__2024-06-17T11:13:55.745913+00:00 [queued]>
[2024-06-17T11:19:17.761+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-17T11:19:17.799+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_process.load_suppliers> on 2024-06-17 11:13:55.745913+00:00
[2024-06-17T11:19:17.823+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=811) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-17T11:19:17.831+0000] {standard_task_runner.py:63} INFO - Started process 844 to run task
[2024-06-17T11:19:17.823+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ELT-PROJECT', 'load_process.load_suppliers', 'manual__2024-06-17T11:13:55.745913+00:00', '--job-id', '116', '--raw', '--subdir', 'DAGS_FOLDER/elt.py', '--cfg-path', '/tmp/tmpytb3sdqs']
[2024-06-17T11:19:17.843+0000] {standard_task_runner.py:91} INFO - Job 116: Subtask load_process.load_suppliers
[2024-06-17T11:19:17.905+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-06-17T11:19:18.012+0000] {task_command.py:426} INFO - Running <TaskInstance: ELT-PROJECT.load_process.load_suppliers manual__2024-06-17T11:13:55.745913+00:00 [running]> on host airflow-scheduler
[2024-06-17T11:19:18.643+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Data-Ninja' AIRFLOW_CTX_DAG_ID='ELT-PROJECT' AIRFLOW_CTX_TASK_ID='load_process.load_suppliers' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T11:13:55.745913+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-06-17T11:13:55.745913+00:00'
[2024-06-17T11:19:18.647+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T11:19:18.654+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-06-17T11:19:18.660+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-17T11:19:19.576+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T11:19:19.577+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/elt.py", line 67, in load
    load_func(df=df, table_names=table)
  File "/local_module/loaders.py", line 33, in load_func
    table_name=table,
               ^^^^^
NameError: name 'table' is not defined. Did you mean: 'tuple'?
[2024-06-17T11:19:19.667+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_categories to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.669+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.695+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_order_details to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.696+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.737+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_customers to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.739+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.777+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_orders to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.779+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.814+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_shippers to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.815+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.862+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_regions to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.864+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.905+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_employees to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.907+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.939+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_employee_territories to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.940+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:19.974+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_products to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:19.975+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:20.014+0000] {taskinstance.py:222} INFO - Forcing task load_process.load_territories to fail due to dag's `fail_stop` setting
[2024-06-17T11:19:20.016+0000] {taskinstance.py:1774} ERROR - Recording the task instance as FAILED
[2024-06-17T11:19:20.050+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=ELT-PROJECT, task_id=load_process.load_suppliers, run_id=manual__2024-06-17T11:13:55.745913+00:00, execution_date=20240617T111355, start_date=20240617T111917, end_date=20240617T111919
[2024-06-17T11:19:20.134+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 116 for task load_process.load_suppliers (name 'table' is not defined; 844)
[2024-06-17T11:19:20.241+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-17T11:19:20.291+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
