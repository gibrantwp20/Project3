[2024-06-17T11:19:18.691+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-17T11:19:18.871+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: ELT-PROJECT.load_process.load_products manual__2024-06-17T11:13:55.745913+00:00 [queued]>
[2024-06-17T11:19:18.938+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: ELT-PROJECT.load_process.load_products manual__2024-06-17T11:13:55.745913+00:00 [queued]>
[2024-06-17T11:19:18.949+0000] {taskinstance.py:2306} INFO - Starting attempt 2 of 2
[2024-06-17T11:19:19.048+0000] {taskinstance.py:2330} INFO - Executing <Task(_PythonDecoratedOperator): load_process.load_products> on 2024-06-17 11:13:55.745913+00:00
[2024-06-17T11:19:19.075+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=827) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2024-06-17T11:19:19.086+0000] {standard_task_runner.py:63} INFO - Started process 877 to run task
[2024-06-17T11:19:19.092+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'ELT-PROJECT', 'load_process.load_products', 'manual__2024-06-17T11:13:55.745913+00:00', '--job-id', '124', '--raw', '--subdir', 'DAGS_FOLDER/elt.py', '--cfg-path', '/tmp/tmpd91g972j']
[2024-06-17T11:19:19.099+0000] {standard_task_runner.py:91} INFO - Job 124: Subtask load_process.load_products
[2024-06-17T11:19:19.171+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/settings.py:195 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-06-17T11:19:19.316+0000] {task_command.py:426} INFO - Running <TaskInstance: ELT-PROJECT.load_process.load_products manual__2024-06-17T11:13:55.745913+00:00 [running]> on host airflow-scheduler
[2024-06-17T11:19:19.822+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Data-Ninja' AIRFLOW_CTX_DAG_ID='ELT-PROJECT' AIRFLOW_CTX_TASK_ID='load_process.load_products' AIRFLOW_CTX_EXECUTION_DATE='2024-06-17T11:13:55.745913+00:00' AIRFLOW_CTX_TRY_NUMBER='2' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-06-17T11:13:55.745913+00:00'
[2024-06-17T11:19:19.827+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-17T11:19:19.833+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-06-17T11:19:19.838+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-06-17T11:19:20.477+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-17T11:19:20.482+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/decorators/base.py", line 265, in execute
    return_value = super().execute(context)
                   ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/elt.py", line 67, in load
    load_func(df=df, table_names=table)
  File "/local_module/loaders.py", line 33, in load_func
    table_name=table,
               ^^^^^
NameError: name 'table' is not defined. Did you mean: 'tuple'?
[2024-06-17T11:19:20.557+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=ELT-PROJECT, task_id=load_process.load_products, run_id=manual__2024-06-17T11:13:55.745913+00:00, execution_date=20240617T111355, start_date=20240617T111918, end_date=20240617T111920
[2024-06-17T11:19:20.580+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 124 for task load_process.load_products (name 'table' is not defined; 877)
[2024-06-17T11:19:20.629+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-06-17T11:19:20.656+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-17T11:19:20.659+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
